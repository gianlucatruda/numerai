{"cells":[{"cell_type":"markdown","metadata":{"id":"r5zRASAHJehY"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1673110899485,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"aL3iB_2z7CWc"},"outputs":[],"source":["MODEL_NAME = 'V3X'\n","MODEL_ID = '<model_id_here>'"]},{"cell_type":"markdown","metadata":{"id":"pL2LDrw1Dwie"},"source":["## Connecting Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27224,"status":"ok","timestamp":1673110927330,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"cPSBYVpJD1-j","outputId":"4f906f5e-f91c-4479-89aa-f8a0a2f7af37"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673110927331,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"NIyKAA9GETgx"},"outputs":[],"source":["from pathlib import Path\n","DIR = Path('gdrive/MyDrive/numerai')\n","DATADIR = DIR / 'data'\n","SRCDIR = DIR / 'src'\n","RESULTDIR = DIR / 'results'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3550,"status":"ok","timestamp":1673110930875,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"lMdQ-fIzUthj"},"outputs":[],"source":["# Copy .env from numerai folder to root dir\n","!cp gdrive/MyDrive/Data/numerai/.env .env"]},{"cell_type":"markdown","metadata":{"id":"ma62H4nY5DOt"},"source":["## Installing and Importing Dependencies\n","First, we install and import the necessary packages. This cell is currently set *not* to print any output; if you run into any issues and need to check for error messages, comment out the `%%capture` line"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17408,"status":"ok","timestamp":1673110948279,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"6fitBsr_ty8_"},"outputs":[],"source":["%%capture\n","# install\n","!pip uninstall --no-input pandas\n","!pip install --upgrade python-dotenv fastai numerapi\n","!pip install ipython-autotime\n","\n","# import dependencies\n","import gc\n","import os\n","from dotenv import load_dotenv, find_dotenv\n","from getpass import getpass\n","import numerapi\n","from fastai.tabular.all import *\n","from pathlib import Path\n","from scipy.stats import spearmanr\n","import sklearn.linear_model\n","\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1673110948280,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"MidvwlsQDl8D","outputId":"05194b17-a491-4d95-902f-3a2820fcf313"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 273 Âµs (started: 2023-01-07 17:02:27 +00:00)\n"]}],"source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","# Set sensible defaults\n","sns.set()\n","sns.set_style(\"ticks\")\n","sns.set_context('paper')\n","\n","%load_ext autotime"]},{"cell_type":"markdown","metadata":{"id":"T8k1mucsueRZ"},"source":["## Setting up numerapi\n","We will use the [numerapi](https://github.com/uuazed/numerapi) package to access the data and make submissions. For this to work, numerapi needs to use your API keys (which can be obtained [here](https://numer.ai/submit)). We will set up two main ways of passing these API keys to a numerapi instance:\n","1. Read a `.env` file using the `python-dotenv` package. This will require you to upload a `.env` file (which contains your secret key and should *not* be kept under version control). Using this method means you will not have to directly enter your keys each time you use this notebook, though you will need to re-upload the `.env` file.\n","2. Manually entering the API keys -- if you don't have access to, or don't want to mess with, your `.env` file.\n","\n","If you have a `.env` file, upload it to the default working directory, `content`, now. In either case, run the cell below to set up the numerapi instance. See [Appendix A](#app_a) for instructions on generating and downloading a .env file."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1673110948280,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"1Z1CS2Uwv79C","outputId":"ac19b5e7-c8b5-4cac-c45f-8dbd793f1041"},"outputs":[],"source":["# Load the numerapi credentials from .env or prompt for them if not available\n","def credential():\n","    dotenv_path = find_dotenv()\n","    load_dotenv(dotenv_path)\n","\n","    if os.getenv(\"NUMERAI_PUBLIC_KEY\"):\n","        print(\"Loaded Numerai Public Key into Global Environment!\")\n","    else:\n","        os.environ[\"NUMERAI_PUBLIC_KEY\"] = getpass(\"Please enter your Numerai Public Key. You can find your key here: https://numer.ai/submit -> \")\n","\n","    if os.getenv(\"NUMERAI_SECRET_KEY\"):\n","        print(\"Loaded Numerai Secret Key into Global Environment!\")\n","    else:\n","        os.environ[\"NUMERAI_SECRET_KEY\"] = getpass(\"Please enter your Numerai Secret Key. You can find your key here: https://numer.ai/submit -> \")\n","\n","    # if os.getenv(\"NUMERAI_MODEL_ID\"):\n","    #     print(\"Loaded Numerai Model ID into Global Environment!\")\n","    # else:\n","    #     os.environ[\"NUMERAI_MODEL_ID\"] = getpass(\"Please enter your Numerai Model ID. You can find your key here: https://numer.ai/submit -> \")\n","\n","credential()\n","public_key = os.environ.get(\"NUMERAI_PUBLIC_KEY\")\n","secret_key = os.environ.get(\"NUMERAI_SECRET_KEY\")\n","# model_id = os.environ.get(\"NUMERAI_MODEL_ID\")\n","model_id = MODEL_ID\n","napi = numerapi.NumerAPI(verbosity=\"info\", public_id=public_key, secret_key=secret_key)"]},{"cell_type":"markdown","metadata":{"id":"w1LhPvUS7RLk"},"source":["You can read up on the functionality of numerapi [here](https://github.com/uuazed/numerapi). You can use it to download the competition data, view other numerai users' public profiles, check submission status, manage your stake, and much more. In this case, we'll only be using it to download competition data and submit predictions.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AWg8UlaTGMWj"},"source":["# Data preparation\n"]},{"cell_type":"markdown","metadata":{"id":"7bVmml-fGQvz"},"source":["## Downloading Competition Data\n","In a more structured project, you'll probably want to keep the data in a seprate directory from your scripts etc. You could also link google colab to your google drive and store the data there in order to avoid needing to download and process the data every time. In this case, however, we'll keep everything in `./content`, and download the data fresh each time."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1292,"status":"ok","timestamp":1673110949565,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"Rs_4xI8pGWj5","outputId":"2885cb36-2fc1-496d-c4b8-30c63a1a7519"},"outputs":[{"name":"stdout","output_type":"stream","text":["new round has started within the last 24hours!\n","time: 882 ms (started: 2023-01-07 17:02:27 +00:00)\n"]}],"source":["# check if a new round has started\n","if napi.check_new_round():\n","    print(\"new round has started within the last 24hours!\")\n","else:\n","    print(\"no new round within the last 24 hours\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62029,"status":"ok","timestamp":1673111011593,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"VcCNcVMv7y1B","outputId":"e330f64c-5bb6-45cf-ce5a-d6cc56e01e73"},"outputs":[{"name":"stderr","output_type":"stream","text":["gdrive/MyDrive/Data/numerai/data/numerai_dataset_394.zip: 488MB [00:28, 17.3MB/s]                           \n"]},{"name":"stdout","output_type":"stream","text":["time: 1min 2s (started: 2023-01-07 17:02:28 +00:00)\n"]}],"source":["# Download the current dataset unless it's already there\n","if not os.path.exists(f'{DATADIR}/numerai_dataset_{napi.get_current_round()}'):\n","    napi.download_current_dataset(dest_path=DATADIR, unzip=True)\n","else:\n","    print(\"Current round already downloaded\")"]},{"cell_type":"markdown","metadata":{"id":"hm7lo6fe8Qsy"},"source":["## Reading the data into memory\n","\n","If you look at the files we downloaded above, you'll see a `numerai_tournament_data.csv` file and a `numerai_training_data.csv` file. The \"tournament\" file contains many rows with targets which we can use for validation, so let's extract those and combine them with our training set. Note that this cell saves a new `csv` after combining the training and validation data, so we can avoid the time-consuming parsing process if we run this cell again in the same session.\n","\n","Question: Does this differ _during_ a tournament?"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":123501,"status":"ok","timestamp":1673111135085,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"bmymMiRn_t3s","outputId":"b42a247a-46e2-453c-9cbe-d8558e85f540"},"outputs":[{"name":"stdout","output_type":"stream","text":["Round number 394\n","Reading training data...\n","Reading tournament data...\n","time: 2min 3s (started: 2023-01-07 17:03:30 +00:00)\n"]}],"source":["# Get the current round\n","ROUND_NUM = napi.get_current_round()\n","print(f\"Round number {ROUND_NUM}\")\n","\n","# training data contains features and targets\n","print('Reading training data...')\n","train_file = Path(f'{DATADIR}/numerai_dataset_{ROUND_NUM}/numerai_training_data.csv')\n","df_train = pd.read_csv(train_file).set_index(\"id\")\n","\n","# tournament data contains features only (for the test rows)\n","print('Reading tournament data...')\n","tourn_file = Path(f'{DATADIR}/numerai_dataset_{ROUND_NUM}/numerai_tournament_data.csv')\n","df_tourn = pd.read_csv(tourn_file).set_index(\"id\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1673111135088,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"6k3Hx2PmIM6k","outputId":"2163dd5d-1aea-4868-9465-6106bd6225c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 2.03 ms (started: 2023-01-07 17:05:34 +00:00)\n"]}],"source":["# Get the names of the features\n","FEAT_COLS = [f for f in df_train.columns if \"feature\" in f]\n","\n","# Get the groups of the features\n","FEAT_GROUPS = {\n","    g: [c for c in FEAT_COLS if c.startswith(f\"feature_{g}\")]\n","    for g in [\"intelligence\", \"wisdom\", \"charisma\", \"dexterity\", \"strength\", \"constitution\"]\n","}"]},{"cell_type":"markdown","metadata":{"id":"ymFRMg3-F1eh"},"source":["## Making the dataframes more memory efficient"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":236541,"status":"ok","timestamp":1673111371621,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"B0lSGRJNv9Yg","outputId":"a70b02ae-2967-4ce6-a4d1-e09650136ec5"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|ââââââââââ| 2/2 [03:56<00:00, 118.29s/it]"]},{"name":"stdout","output_type":"stream","text":["time: 3min 56s (started: 2023-01-07 17:05:34 +00:00)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Convert all features (and target) to float16 to save memory\n","for _df in tqdm([df_train, df_tourn]):\n","    _df[[*FEAT_COLS, 'target']] = _df[[*FEAT_COLS, 'target']].astype(np.float16)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1259,"status":"ok","timestamp":1673111372875,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"ArPNfbdEFqno","outputId":"d5d79718-391e-4afe-a1d9-00af4775b6c7"},"outputs":[],"source":["# Copy tournament data into validation\n","df_val = df_tourn[df_tourn['data_type'] == 'validation']\n","# Remove df_tourn from memory\n","del df_tourn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1673111372876,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"ix-LlH2oKLWW","outputId":"1674d7dc-8f1c-4a3b-c2f7-5f34c13b134d"},"outputs":[],"source":["# Convert era to int32\n","pd.options.mode.chained_assignment = 'warn'\n","df_train['era'] = df_train['era'].str[3:].astype('int32')\n","df_val['era'] = df_val['era'].str[3:].astype('int32')"]},{"cell_type":"markdown","metadata":{"id":"8BSr1BMR5Ilh"},"source":["# Modeling the Data\n","\n","In this section, we will define our evaluation metrics; run two different models (a linear regression model from `scikit-learn` and a neural network from `fastai`); and generate submission dataframes from those files."]},{"cell_type":"markdown","metadata":{"id":"WeYfQcry6svF"},"source":["## Evaluation Metrics\n","\n","In this section, we will define two key evaluation metrics used to assess the performance of models before submitting to the tournament. These metrics are:\n","- Average Spearman Correlation per era: The sum of each era's Spearman correlation divided by the number of eras.\n","- Sharpe Ratio: The average correlation per era divided by the standard deviation of the correlations per era.\n","\n","Both are defined in reasonable detail [here](https://wandb.ai/carlolepelaars/numerai_tutorial/reports/How-to-get-Started-With-Numerai--VmlldzoxODU0NTQ). The methods defined below are modified versions of the methods described in that post."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1673111372877,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"DtFniCX98z6i","outputId":"7662f431-b617-4bb3-f24f-d8fc3653cbd0"},"outputs":[],"source":["def score_corr(df: pd.DataFrame) -> np.float32:\n","    \"\"\"\n","    Calculate the correlation by using grouped per-era data\n","    :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and \"prediction\"\n","    :return: The average per-era correlations.\n","    \"\"\"\n","    def _score(sub_df: pd.DataFrame) -> np.float32:\n","        \"\"\" Calculate Spearman correlation for Pandas' apply method \"\"\"\n","        return spearmanr(sub_df[\"target\"],  sub_df[\"prediction\"])[0]\n","    corrs = df.groupby(\"era\").apply(_score)\n","    return corrs.mean()\n","\n","def score_spear(y_true, y_pred, axis=0):\n","    \"\"\"Calculate Spearman correlation\"\"\"\n","    return spearmanr(y_true, y_pred, axis=axis)[0]\n","\n","def score_sharpe(df: pd.DataFrame) -> np.float32:\n","    \"\"\"\n","    Calculate the Sharpe ratio by using grouped per-era data\n","    :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and \"prediction\"\n","    :return: The Sharpe ratio for your predictions.\n","    \"\"\"\n","    def _score(sub_df: pd.DataFrame) -> np.float32:\n","        \"\"\" Calculate Spearman correlation for Pandas' apply method \"\"\"\n","        return spearmanr(sub_df[\"target\"],  sub_df[\"prediction\"])[0]\n","    corrs = df.groupby(\"era\").apply(_score)\n","    return corrs.mean() / corrs.std()\n","\n","def scores(df: pd.DataFrame, verbose=False) -> (np.float32, np.float32):\n","    \"\"\" Score models Spearman and Sharpe. \"\"\"\n","    val_sharpe = score_sharpe(df)\n","    val_corr = score_corr(df)\n","    if verbose:\n","        print(f'\\nSpearman:\\t{val_corr: .4f}\\nSharpe:\\t\\t{val_sharpe: .4f}')\n","    return val_corr, val_sharpe\n","\n","def validate_preds(preds, df_val: pd.DataFrame, verbose=True):\n","    _df = pd.DataFrame({'prediction':preds,\n","                        'target':df_val.target,\n","                        'era':df_val.era}).reset_index()\n","\n","    return scores(_df, verbose=verbose)\n"]},{"cell_type":"markdown","metadata":{"id":"I4azmVvR6ZhT"},"source":["## Training models"]},{"cell_type":"markdown","metadata":{"id":"Q3qwFNYGF5TB"},"source":["### Linear baseline\n","This model closely follows the tutorial example [here](https://colab.research.google.com/github/numerai/example-scripts/blob/master/making-your-first-submission-on-numerai.ipynb). We will use the `scikit-learn` package, with which we can implement and fit our regression model in just a couple of lines of code."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11747,"status":"ok","timestamp":1673111384617,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"qKG75I7-yKvA","outputId":"5c46c238-0187-40b3-9b60-34b1deaddfda"},"outputs":[],"source":["model = sklearn.linear_model.LinearRegression()\n","model = model.fit(df_train[FEAT_COLS], df_train['target'])"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1392,"status":"ok","timestamp":1673111386006,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"wgU0Pz9x9vpv","outputId":"191d5d15-0561-4397-9852-27139fdd303b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Spearman:\t 0.0162\n","Sharpe:\t\t 0.5237\n","time: 1.01 s (started: 2023-01-07 17:09:44 +00:00)\n"]}],"source":["val_preds = model.predict(df_val[FEAT_COLS])\n","_df = pd.DataFrame({'prediction':val_preds,\n","                        'target':df_val.target,\n","                        'era':df_val.era}).reset_index()\n","\n","corr_val, sharpe_val = scores(_df, verbose=True)"]},{"cell_type":"markdown","metadata":{"id":"ZF1m77ij33wT"},"source":["## Ensemble model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1673111386007,"user":{"displayName":"Gianluca Truda","userId":"10545274143306236899"},"user_tz":0},"id":"SvGHkM5viubn","outputId":"bb3c49ba-27e7-45ca-ca42-6a60e02a808f"},"outputs":[],"source":["from xgboost import XGBRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.linear_model import LassoCV, RidgeCV\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.decomposition import PCA\n","from sklearn.base import BaseEstimator\n","from sklearn.metrics import mean_squared_error, make_scorer\n","\n","class EraEnsemble(BaseEstimator):\n","    def __init__(self,\n","                 n_subs=10,\n","                 pca_frac=None,\n","                 subalg=XGBRegressor,\n","                #  subalg_args={},\n","                 mainalg=LassoCV,\n","                #  mainalg_args={},\n","                 ):\n","        self.n_subs = n_subs\n","        self.submodels = []\n","        self.sub_preds = []\n","        self.pca_frac = pca_frac\n","        self.transforms = []\n","        self.subalg = subalg\n","        self.mainalg = mainalg\n","        # self.subalg_args = subalg_args,\n","        # self.mainalg_args = mainalg_args\n","\n","    def get_params(self, *args, **kwargs):\n","        return {\n","            'n_subs': self.n_subs,\n","            'pca_frac': self.pca_frac,\n","            'subalg': self.subalg,\n","            'mainalg': self.mainalg,\n","            }\n","\n","    def fit(self, df, y, validation=df_val):\n","        # Figure out how to partition eras\n","        n_eras = df.era.nunique()\n","        min_era = df.era.min()\n","        max_era = df.era.max()\n","        STEP = n_eras//self.n_subs\n","\n","        # Loop over era ranges\n","        for i in range(min_era, max_era, STEP):\n","            _data = df[df.era.between(i, i+STEP)]\n","            _target = _data['target']\n","            _data = _data[FEAT_COLS]\n","            if self.pca_frac < 1.0:\n","                _pca = PCA(n_components=self.pca_frac).fit(_data)\n","                _data = _pca.transform(_data)\n","                self.transforms.append(_pca)\n","            if self.subalg == XGBRegressor:\n","                submodel = self.subalg(verbosity=0).fit(_data, _target)\n","            else:\n","                submodel = self.subalg().fit(_data, _target)\n","            self.submodels.append(submodel)\n","            if self.pca_frac < 1.0:\n","                _preds = submodel.predict(_pca.transform(df[FEAT_COLS]))\n","            else:\n","                _preds = submodel.predict(df[FEAT_COLS])\n","            self.sub_preds.append(_preds)\n","            # if self.use_pca:\n","            #     _val_preds = submodel.predict(_pca.transform(df_val[FEAT_COLS]))\n","            # else:\n","            #     _val_preds = submodel.predict(df_val[FEAT_COLS])\n","            # corr_val, sharpe_val = validate_preds(_val_preds, df_val)\n","        _X = np.array(self.sub_preds).T\n","        self.mainmodel = self.mainalg().fit(_X, y)\n","\n","        return self\n","\n","    def predict(self, df):\n","        _preds = []\n","        for i, sm in enumerate(self.submodels):\n","            if self.pca_frac < 1.0:\n","                _data = self.transforms[i].transform(df[FEAT_COLS])\n","            else:\n","                _data = df[FEAT_COLS]\n","            _preds.append(sm.predict(_data))\n","        _X = np.array(_preds).T\n","\n","        return self.mainmodel.predict(_X)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Iqtjh_x1wnZC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model...\n","\n","Spearman:\t 0.0215\n","Sharpe:\t\t 0.7300\n","time: 6min 14s (started: 2023-01-07 17:09:45 +00:00)\n"]}],"source":["MODEL_FILE = SRCDIR / 'era_ensemble_v3x.xgb'\n","RETRAIN_MODEL = True\n","\n","model = EraEnsemble(\n","    mainalg=RidgeCV,\n","    n_subs=3,\n","    pca_frac=1.0,\n","    subalg=XGBRegressor,\n",")\n","\n","# TODO develop techniques for saving and loading custom ensemble model\n","\n","if MODEL_FILE.is_file() and not RETRAIN_MODEL:\n","    print(f\"Loading pre-trained model from '{MODEL_FILE}' ...\")\n","    model.load_model(str(MODEL_FILE))\n","else:\n","    print(\"Training model...\")\n","    model.fit(df_train, df_train['target'])\n","    # print(f\"Saving model to '{MODEL_FILE}' ...\")\n","    # model.save_model(str(MODEL_FILE))\n","\n","preds = model.predict(df_val)\n","val_corr, val_sharpe = validate_preds(preds, df_val)"]},{"cell_type":"markdown","metadata":{"id":"oRLGopZF0r7T"},"source":["#### Making Predictions with the last Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nOeJjJdZ08aV"},"outputs":[{"name":"stderr","output_type":"stream","text":["22it [02:17,  6.26s/it]\n"]},{"name":"stdout","output_type":"stream","text":["(2175811, 2)\n","time: 2min 18s (started: 2023-01-07 17:15:59 +00:00)\n"]}],"source":["ids = []\n","preds = []\n","\n","# Read and predict in chunks to prevent memory issues\n","tourn_iter_csv = pd.read_csv(tourn_file, iterator=True, chunksize=1e5)\n","for chunk in tqdm(tourn_iter_csv):\n","    df = chunk[FEAT_COLS]\n","    out = model.predict(df)\n","    ids.extend(chunk[\"id\"])\n","    preds.extend(out)\n","tourn_iter_csv.close()\n","\n","df_predictions = pd.DataFrame({\n","    'id':ids,\n","    'prediction':preds\n","})\n","df_predictions.head()\n","print(df_predictions.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xg_HdPki6Mh3"},"outputs":[],"source":["PRED_FILENAME = f\"{RESULTDIR}/predictions_{MODEL_NAME}_{napi.get_current_round()}.csv\"\n","df_predictions.to_csv(PRED_FILENAME, index=False)"]},{"cell_type":"markdown","metadata":{"id":"dRxfYqICVYqv"},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j8UaXQTNVayb"},"outputs":[],"source":["if PRED_FILENAME is not None:\n","    napi.upload_predictions(PRED_FILENAME, model_id=MODEL_ID)"]}],"metadata":{"colab":{"machine_shape":"hm","name":"","provenance":[{"file_id":"13R96PoB-uGcSbVQfP-mHOUiB-_4scdxv","timestamp":1616097407537},{"file_id":"1ThGqqcA8wc4zuHtolgmAH3m2JrdTZvke","timestamp":1615423425596},{"file_id":"10V6YOGzzgUPBW7trzG95ZicF8cTf_thO","timestamp":1615416690624},{"file_id":"https://github.com/djliden/numerai_starter_kit/blob/main/Numerai_Starter_Kit.ipynb","timestamp":1615411818997}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
